{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poonam Ligade\n",
    "1st Feb 2017\n",
    "This notebook is like note to self.\n",
    "I am trying to understand various components of Artificial Neural Networks aka Deep Learning.\n",
    "Hope it might be useful for someone else here.\n",
    "I am designing neural net on MNIST handwritten digits images to identify their correct label i.e number in image.\n",
    "You must have guessed its an image recognition task.\n",
    "MNIST is called Hello world of Deep learning.\n",
    "Lets start!!\n",
    "This notebook is inspired from Jeremy's Deep Learning mooc and Deep learning with python book by Keras author François Chollet .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the training & test sets, skipping the header row with [1:]\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= pd.read_csv(\"test.csv\")\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = (train.ix[:,1:].values).astype('float32') # all pixel values\n",
    "y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits\n",
    "X_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable is an integer from 0 to 9. This is a multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAABvCAYAAABVcfMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCOsfSH8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb430adcf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Convert train datset to (num_images, img_rows, img_cols) format \n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "\n",
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#expand 1 more dimention as 1 for colour channel gray\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the digit images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x): \n",
    "    return (x-mean_px)/std_px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.677589"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding of labels.\n",
    "\n",
    "A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension.\n",
    "\n",
    "In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
    "\n",
    "For example, 3 would be [0,0,0,1,0,0,0,0,0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train= to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot 10th label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCncRkRhSuIuIxND/B8aM+oD/trEAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4326286d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(y_train[9])\n",
    "plt.plot(y_train[9])\n",
    "plt.xticks(range(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing neural network architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import  Sequential\n",
    "from keras.layers.core import  Lambda , Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a simple model from Keras Sequential layer.\n",
    "\n",
    "Lambda layer performs simple arithmetic operations like sum, average, exponentiation etc.\n",
    "\n",
    "In 1st layer of the model we have to define input dimensions of our data in (rows,columns,colour channel) format.\n",
    "(In theano colour channel comes first)\n",
    "\n",
    "Flatten will transform input into 1D array.\n",
    "\n",
    "Dense is fully connected layer that means all neurons in previous layers will be connected to all neurons in fully connected layer.\n",
    "In the last layer we have to specify output dimensions/classes of the model.\n",
    "Here it's 10, since we have to output 10 different digit labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape  (None, 28, 28, 1)\n",
      "output shape  (None, 10)\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Lambda(standardize,input_shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"input shape \",model.input_shape)\n",
    "print(\"output shape \",model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile network\n",
    "\n",
    "Before making network ready for training we have to make sure to add below things:\n",
    "A loss function: to measure how good the network is\n",
    "An optimizer: to update network as it sees more data and reduce loss value\n",
    "Metrics: to monitor performance of network\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam ,RMSprop\n",
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "gen = image.ImageDataGenerator()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches=gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batches.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 6s - loss: 0.4809 - acc: 0.8542 - val_loss: 0.3369 - val_acc: 0.9026\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu',input_dim=(28 * 28)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.0001), loss='categorical_crossentropy',\n",
    " metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(train_images, train_labels, \n",
    "            epochs=15, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs we can see that training loss is decreasing and training accuracy is increasing slowly. Thats what we intended to do using gradient descent.\n",
    "But thats not the case with validation set\n",
    "after 15th epoch val_loss is increasing and val_acc is decreasing.\n",
    "That is called as **overfitting**.\n",
    "\n",
    "after the second epoch, we are over optimising on the training data, and we ended up learning representations that are specific to the training data and do not generalize to data outside of the training set\n",
    "\n",
    "To avoid this we will simply stop training after 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 5s - loss: 0.3078 - acc: 0.9118 - val_loss: 0.3197 - val_acc: 0.9064\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.1\n",
    "history=model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39900 samples, validate on 2100 samples\n",
      "Epoch 1/3\n",
      "39900/39900 [==============================] - 1s - loss: 0.2427 - acc: 0.9309 - val_loss: 0.3225 - val_acc: 0.9186\n",
      "Epoch 2/3\n",
      "39900/39900 [==============================] - 1s - loss: 0.2424 - acc: 0.9314 - val_loss: 0.3247 - val_acc: 0.9186\n",
      "Epoch 3/3\n",
      "39900/39900 [==============================] - 1s - loss: 0.2405 - acc: 0.9304 - val_loss: 0.3139 - val_acc: 0.9171\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.01\n",
    "history=model.fit(X_train, y_train,validation_split = 0.05, \n",
    "            nb_epoch=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fully_connected_model():\n",
    "    model=Sequential([Lambda(standardize,input_shape=(28,28,1)),\n",
    "                     Flatten(),\n",
    "                     Dense(512,activation='relu'),\n",
    "                     Dense(10, activation='softmax')])\n",
    "    model.compile(Adam(),metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model=get_fully_connected_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38220 samples, validate on 3780 samples\n",
      "Epoch 1/3\n",
      "2s - loss: 0.2263 - acc: 0.9305 - val_loss: 0.1385 - val_acc: 0.9569\n",
      "Epoch 2/3\n",
      "2s - loss: 0.0928 - acc: 0.9714 - val_loss: 0.1019 - val_acc: 0.9690\n",
      "Epoch 3/3\n",
      "2s - loss: 0.0603 - acc: 0.9806 - val_loss: 0.1081 - val_acc: 0.9685\n"
     ]
    }
   ],
   "source": [
    "history=fc_model.fit(X_train, y_train,validation_split = 0.09, \n",
    "            nb_epoch=3, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/5\n",
      "2s - loss: 0.0074 - acc: 0.9979 - val_loss: 0.1373 - val_acc: 0.9783\n",
      "Epoch 2/5\n",
      "2s - loss: 0.0070 - acc: 0.9979 - val_loss: 0.1227 - val_acc: 0.9793\n",
      "Epoch 3/5\n",
      "2s - loss: 0.0089 - acc: 0.9975 - val_loss: 0.1413 - val_acc: 0.9774\n",
      "Epoch 4/5\n",
      "1s - loss: 0.0069 - acc: 0.9976 - val_loss: 0.1172 - val_acc: 0.9788\n",
      "Epoch 5/5\n",
      "1s - loss: 0.0128 - acc: 0.9964 - val_loss: 0.1470 - val_acc: 0.9764\n"
     ]
    }
   ],
   "source": [
    "fc_model.optimizer.lr=0.001\n",
    "history=fc_model.fit(X_train, y_train,validation_split = 0.10, \n",
    "            nb_epoch=5, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    model=Sequential([\n",
    "                        Lambda(standardize,input_shape=(28,28,1)),\n",
    "                        Convolution2D(32,3,3,activation='relu'),\n",
    "                        Convolution2D(32,3,3,activation='relu'),\n",
    "                        MaxPooling2D(pool_size=(2,2)),\n",
    "                        Convolution2D(64,3,3,activation='relu'),\n",
    "                        Convolution2D(64,3,3,activation='relu'),\n",
    "                        MaxPooling2D(pool_size=(2,2)),\n",
    "                        Flatten(),\n",
    "                        Dense(512,activation='relu'),\n",
    "                        Dense(10, activation='softmax')\n",
    "                     ])\n",
    "    model.compile(Adam(),metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model=get_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/2\n",
      "5s - loss: 0.1477 - acc: 0.9548 - val_loss: 0.0529 - val_acc: 0.9848\n",
      "Epoch 2/2\n",
      "4s - loss: 0.0425 - acc: 0.9873 - val_loss: 0.0301 - val_acc: 0.9895\n"
     ]
    }
   ],
   "source": [
    "history=cnn_model.fit(X_train, y_train,validation_split = 0.10, \n",
    "            nb_epoch=2, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/2\n",
      "4s - loss: 0.0177 - acc: 0.9946 - val_loss: 0.0270 - val_acc: 0.9910\n",
      "Epoch 2/2\n",
      "4s - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0386 - val_acc: 0.9900\n"
     ]
    }
   ],
   "source": [
    "cnn_model.optimizer.lr=0.01\n",
    "history=cnn_model.fit(X_train, y_train,validation_split = 0.10, \n",
    "            nb_epoch=2, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen=image.ImageDataGenerator(\n",
    "    zca_whitening=True, rotation_range=8.0, width_shift_range=0.8, height_shift_range=0.08, shear_range=0.3,\n",
    "    zoom_range=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = gen.flow(X_train, y_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/2\n",
      "4s - loss: 0.0300 - acc: 0.9901 - val_loss: 0.0374 - val_acc: 0.9879\n",
      "Epoch 2/2\n",
      "4s - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0266 - val_acc: 0.9914\n"
     ]
    }
   ],
   "source": [
    "cnn_model.optimizer.lr=0.01\n",
    "history=cnn_model.fit(X_train, y_train,validation_split = 0.10, \n",
    "            nb_epoch=2, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_model():\n",
    "    model = Sequential([\n",
    "                        Lambda(standardize,input_shape=(28,28,1)),\n",
    "                        Convolution2D(32,3,3,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        Convolution2D(32,3,3,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        MaxPooling2D(pool_size=(2,2)),\n",
    "                        Convolution2D(64,3,3,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        Convolution2D(64,3,3,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        MaxPooling2D(pool_size=(2,2)),\n",
    "                        Flatten(),\n",
    "                        Dense(512,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model=get_bn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/2\n",
      "9s - loss: 0.0401 - acc: 0.9871 - val_loss: 0.0436 - val_acc: 0.9848\n",
      "Epoch 2/2\n",
      "9s - loss: 0.0292 - acc: 0.9903 - val_loss: 0.0312 - val_acc: 0.9907\n"
     ]
    }
   ],
   "source": [
    "history=bn_model.fit(X_train, y_train,validation_split = 0.10, \n",
    "            nb_epoch=2, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/2\n",
      "9s - loss: 0.0207 - acc: 0.9936 - val_loss: 0.0416 - val_acc: 0.9862\n",
      "Epoch 2/2\n",
      "9s - loss: 0.0186 - acc: 0.9939 - val_loss: 0.0231 - val_acc: 0.9924\n"
     ]
    }
   ],
   "source": [
    "bn_model.optimizer.lr=0.01\n",
    "history=bn_model.fit(X_train, y_train,validation_split = 0.10, \n",
    "            nb_epoch=2, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "9s - loss: 0.1017 - acc: 0.9682 - val_loss: 0.0525 - val_acc: 0.9821\n",
      "Epoch 2/15\n",
      "8s - loss: 0.0372 - acc: 0.9885 - val_loss: 0.0595 - val_acc: 0.9831\n",
      "Epoch 3/15\n",
      "8s - loss: 0.0280 - acc: 0.9913 - val_loss: 0.0329 - val_acc: 0.9907\n",
      "Epoch 4/15\n",
      "8s - loss: 0.0241 - acc: 0.9921 - val_loss: 0.0281 - val_acc: 0.9919\n",
      "Epoch 5/15\n",
      "8s - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0400 - val_acc: 0.9876\n",
      "Epoch 6/15\n",
      "8s - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0394 - val_acc: 0.9879\n",
      "Epoch 7/15\n",
      "7s - loss: 0.0141 - acc: 0.9960 - val_loss: 0.0346 - val_acc: 0.9902\n",
      "Epoch 8/15\n",
      "8s - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0296 - val_acc: 0.9919\n",
      "Epoch 9/15\n",
      "8s - loss: 0.0110 - acc: 0.9966 - val_loss: 0.0279 - val_acc: 0.9914\n",
      "Epoch 10/15\n",
      "8s - loss: 0.0111 - acc: 0.9965 - val_loss: 0.0274 - val_acc: 0.9933\n",
      "Epoch 11/15\n",
      "8s - loss: 0.0120 - acc: 0.9961 - val_loss: 0.0339 - val_acc: 0.9917\n",
      "Epoch 12/15\n",
      "8s - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0284 - val_acc: 0.9936\n",
      "Epoch 13/15\n",
      "8s - loss: 0.0089 - acc: 0.9976 - val_loss: 0.0290 - val_acc: 0.9929\n",
      "Epoch 14/15\n",
      "8s - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0273 - val_acc: 0.9924\n",
      "Epoch 15/15\n",
      "8s - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0386 - val_acc: 0.9881\n"
     ]
    }
   ],
   "source": [
    "bn_model.optimizer.lr=0.001\n",
    "history=bn_model.fit(X_train, y_train,validation_split = 0.10, \n",
    "            nb_epoch=15, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Adding Dropout layer to prevent overfitting of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_with_dropout_model():\n",
    "    model = Sequential([\n",
    "                        Lambda(standardize,input_shape=(28,28,1)),\n",
    "                        Convolution2D(32,3,3,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        Convolution2D(64,3,3,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        MaxPooling2D(pool_size=(2,2)),\n",
    "                        Convolution2D(128,3,3,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        Convolution2D(128,3,3,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        MaxPooling2D(pool_size=(2,2)),\n",
    "                        Flatten(),\n",
    "                        Dense(512,activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        Dropout(0.5),\n",
    "                        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/15\n",
      "12s - loss: 0.1259 - acc: 0.9618 - val_loss: 0.0920 - val_acc: 0.9719\n",
      "Epoch 2/15\n",
      "10s - loss: 0.0474 - acc: 0.9850 - val_loss: 0.0503 - val_acc: 0.9864\n",
      "Epoch 3/15\n",
      "10s - loss: 0.0393 - acc: 0.9880 - val_loss: 0.0224 - val_acc: 0.9929\n",
      "Epoch 4/15\n",
      "10s - loss: 0.0312 - acc: 0.9903 - val_loss: 0.0248 - val_acc: 0.9921\n",
      "Epoch 5/15\n",
      "10s - loss: 0.0273 - acc: 0.9911 - val_loss: 0.0311 - val_acc: 0.9886\n",
      "Epoch 6/15\n",
      "10s - loss: 0.0245 - acc: 0.9917 - val_loss: 0.0241 - val_acc: 0.9929\n",
      "Epoch 7/15\n",
      "10s - loss: 0.0227 - acc: 0.9928 - val_loss: 0.0238 - val_acc: 0.9933\n",
      "Epoch 8/15\n",
      "10s - loss: 0.0209 - acc: 0.9928 - val_loss: 0.0288 - val_acc: 0.9924\n",
      "Epoch 9/15\n",
      "10s - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0344 - val_acc: 0.9905\n",
      "Epoch 10/15\n",
      "10s - loss: 0.0176 - acc: 0.9940 - val_loss: 0.0365 - val_acc: 0.9893\n",
      "Epoch 11/15\n",
      "10s - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0331 - val_acc: 0.9898\n",
      "Epoch 12/15\n",
      "10s - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0247 - val_acc: 0.9929\n",
      "Epoch 13/15\n",
      "10s - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0269 - val_acc: 0.9924\n",
      "Epoch 14/15\n",
      "10s - loss: 0.0117 - acc: 0.9964 - val_loss: 0.0367 - val_acc: 0.9900\n",
      "Epoch 15/15\n",
      "10s - loss: 0.0132 - acc: 0.9960 - val_loss: 0.0245 - val_acc: 0.9929\n"
     ]
    }
   ],
   "source": [
    "bn_with_dropout_model = get_bn_with_dropout_model()\n",
    "\n",
    "bn_with_dropout_model.optimizer.lr=0.001\n",
    "history=bn_with_dropout_model.fit(X_train, y_train,validation_split = 0.10, \n",
    "            nb_epoch=15, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10s - loss: 0.1358 - acc: 0.9584\n",
      "Epoch 2/15\n",
      "9s - loss: 0.0510 - acc: 0.9844\n",
      "Epoch 3/15\n",
      "9s - loss: 0.0401 - acc: 0.9873\n",
      "Epoch 4/15\n",
      "9s - loss: 0.0317 - acc: 0.9892\n",
      "Epoch 5/15\n",
      "10s - loss: 0.0298 - acc: 0.9900\n",
      "Epoch 6/15\n",
      "9s - loss: 0.0254 - acc: 0.9916\n",
      "Epoch 7/15\n",
      "10s - loss: 0.0241 - acc: 0.9925\n",
      "Epoch 8/15\n",
      "10s - loss: 0.0227 - acc: 0.9930\n",
      "Epoch 9/15\n",
      "10s - loss: 0.0192 - acc: 0.9939\n",
      "Epoch 10/15\n",
      "10s - loss: 0.0166 - acc: 0.9950\n",
      "Epoch 11/15\n",
      "10s - loss: 0.0170 - acc: 0.9948\n",
      "Epoch 12/15\n",
      "10s - loss: 0.0151 - acc: 0.9952\n",
      "Epoch 13/15\n",
      "10s - loss: 0.0123 - acc: 0.9959\n",
      "Epoch 14/15\n",
      "9s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 15/15\n",
      "9s - loss: 0.0121 - acc: 0.9956\n"
     ]
    }
   ],
   "source": [
    "bn_with_dropout_model = get_bn_with_dropout_model()\n",
    "\n",
    "bn_with_dropout_model.optimizer.lr=0.001\n",
    "history=bn_with_dropout_model.fit(X_train, y_train, \n",
    "            nb_epoch=15, batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = bn_with_dropout_model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"DR.csv\", index=False, header=True)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble():\n",
    "    bn_with_dropout_model = get_bn_with_dropout_model()\n",
    "\n",
    "    bn_with_dropout_model.optimizer.lr=0.1\n",
    "    history=bn_with_dropout_model.fit(X_train, y_train,\n",
    "            nb_epoch=2, batch_size=64,verbose=2)\n",
    "    \n",
    "    bn_with_dropout_model.optimizer.lr=0.01\n",
    "    history=bn_with_dropout_model.fit(X_train, y_train, \n",
    "            nb_epoch=4, batch_size=64,verbose=2)\n",
    "    \n",
    "    bn_with_dropout_model.optimizer.lr=0.001\n",
    "    history=bn_with_dropout_model.fit(X_train, y_train, \n",
    "            nb_epoch=8, batch_size=64,verbose=2)\n",
    "    \n",
    "    bn_with_dropout_model.optimizer.lr=0.0001\n",
    "    history=bn_with_dropout_model.fit(X_train, y_train, \n",
    "            nb_epoch=15, batch_size=64,verbose=2)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "13s - loss: 2.6668 - acc: 0.8164\n",
      "Epoch 2/2\n",
      "11s - loss: 3.4081 - acc: 0.7865\n",
      "Epoch 1/4\n",
      "11s - loss: 3.6669 - acc: 0.7714\n",
      "Epoch 2/4\n",
      "11s - loss: 2.7606 - acc: 0.8279\n",
      "Epoch 3/4\n",
      "11s - loss: 2.8856 - acc: 0.8205\n",
      "Epoch 4/4\n",
      "11s - loss: 2.5801 - acc: 0.8396\n",
      "Epoch 1/8\n",
      "10s - loss: 2.9881 - acc: 0.8143\n",
      "Epoch 2/8\n",
      "11s - loss: 2.3233 - acc: 0.8557\n",
      "Epoch 3/8\n",
      "11s - loss: 3.6671 - acc: 0.7721\n",
      "Epoch 4/8\n",
      "11s - loss: 3.5769 - acc: 0.7777\n",
      "Epoch 5/8\n",
      "11s - loss: 3.5357 - acc: 0.7804\n",
      "Epoch 6/8\n",
      "10s - loss: 3.2879 - acc: 0.7959\n",
      "Epoch 7/8\n",
      "11s - loss: 3.0311 - acc: 0.8117\n",
      "Epoch 8/8\n",
      "11s - loss: 3.0747 - acc: 0.8091\n",
      "Epoch 1/15\n",
      "11s - loss: 2.4926 - acc: 0.8453\n",
      "Epoch 2/15\n",
      "11s - loss: 2.3098 - acc: 0.8565\n",
      "Epoch 3/15\n",
      "11s - loss: 2.8299 - acc: 0.8243\n",
      "Epoch 4/15\n",
      "11s - loss: 3.3804 - acc: 0.7900\n",
      "Epoch 5/15\n",
      "11s - loss: 3.0954 - acc: 0.8078\n",
      "Epoch 6/15\n",
      "12s - loss: 2.2307 - acc: 0.8615\n",
      "Epoch 7/15\n",
      "12s - loss: 2.5426 - acc: 0.8422\n",
      "Epoch 8/15\n",
      "11s - loss: 2.2381 - acc: 0.8610\n",
      "Epoch 9/15\n",
      "11s - loss: 2.8919 - acc: 0.8205\n",
      "Epoch 10/15\n",
      "11s - loss: 2.3772 - acc: 0.8524\n",
      "Epoch 11/15\n",
      "11s - loss: 2.3634 - acc: 0.8533\n",
      "Epoch 12/15\n",
      "11s - loss: 2.6890 - acc: 0.8331\n",
      "Epoch 13/15\n",
      "12s - loss: 2.0934 - acc: 0.8700\n",
      "Epoch 14/15\n",
      "12s - loss: 2.3238 - acc: 0.8558\n",
      "Epoch 15/15\n",
      "12s - loss: 2.5430 - acc: 0.8421\n",
      "Epoch 1/2\n",
      "12s - loss: 2.9124 - acc: 0.8004\n",
      "Epoch 2/2\n",
      "11s - loss: 3.6653 - acc: 0.7704\n",
      "Epoch 1/4\n",
      "11s - loss: 2.9493 - acc: 0.8159\n",
      "Epoch 2/4\n",
      "11s - loss: 3.2079 - acc: 0.8000\n",
      "Epoch 3/4\n",
      "12s - loss: 3.1019 - acc: 0.8069\n",
      "Epoch 4/4\n",
      "12s - loss: 3.3578 - acc: 0.7913\n",
      "Epoch 1/8\n",
      "11s - loss: 3.1423 - acc: 0.8047\n",
      "Epoch 2/8\n",
      "11s - loss: 2.8837 - acc: 0.8207\n",
      "Epoch 3/8\n",
      "11s - loss: 3.5469 - acc: 0.7796\n",
      "Epoch 4/8\n",
      "12s - loss: 2.9704 - acc: 0.8155\n",
      "Epoch 5/8\n",
      "11s - loss: 2.3420 - acc: 0.8545\n",
      "Epoch 6/8\n",
      "12s - loss: 2.6759 - acc: 0.8338\n",
      "Epoch 7/8\n",
      "12s - loss: 2.3503 - acc: 0.8540\n",
      "Epoch 8/8\n",
      "11s - loss: 2.9977 - acc: 0.8139\n",
      "Epoch 1/15\n",
      "12s - loss: 2.7175 - acc: 0.8312\n",
      "Epoch 2/15\n",
      "11s - loss: 2.4682 - acc: 0.8467\n",
      "Epoch 3/15\n",
      "11s - loss: 2.7118 - acc: 0.8316\n",
      "Epoch 4/15\n",
      "11s - loss: 3.1439 - acc: 0.8048\n",
      "Epoch 5/15\n",
      "11s - loss: 4.7965 - acc: 0.7023\n",
      "Epoch 6/15\n",
      "11s - loss: 2.6608 - acc: 0.8348\n",
      "Epoch 7/15\n",
      "11s - loss: 2.3405 - acc: 0.8547\n",
      "Epoch 8/15\n",
      "12s - loss: 2.3896 - acc: 0.8516\n",
      "Epoch 9/15\n",
      "11s - loss: 2.6137 - acc: 0.8378\n",
      "Epoch 10/15\n",
      "11s - loss: 2.2228 - acc: 0.8620\n",
      "Epoch 11/15\n",
      "12s - loss: 2.2852 - acc: 0.8581\n",
      "Epoch 12/15\n",
      "11s - loss: 3.1312 - acc: 0.8056\n",
      "Epoch 13/15\n",
      "12s - loss: 3.0516 - acc: 0.8105\n",
      "Epoch 14/15\n",
      "11s - loss: 2.5876 - acc: 0.8394\n",
      "Epoch 15/15\n",
      "11s - loss: 2.7039 - acc: 0.8321\n",
      "Epoch 1/2\n",
      "13s - loss: 3.5864 - acc: 0.7594\n",
      "Epoch 2/2\n",
      "11s - loss: 4.1930 - acc: 0.7378\n",
      "Epoch 1/4\n",
      "12s - loss: 4.2437 - acc: 0.7356\n",
      "Epoch 2/4\n",
      "12s - loss: 4.3869 - acc: 0.7271\n",
      "Epoch 3/4\n",
      "11s - loss: 4.4958 - acc: 0.7204\n",
      "Epoch 4/4\n",
      "11s - loss: 3.8604 - acc: 0.7601\n",
      "Epoch 1/8\n",
      "11s - loss: 4.0500 - acc: 0.7483\n",
      "Epoch 2/8\n",
      "11s - loss: 3.7744 - acc: 0.7654\n",
      "Epoch 3/8\n",
      "11s - loss: 3.6552 - acc: 0.7728\n",
      "Epoch 4/8\n",
      "11s - loss: 3.5238 - acc: 0.7812\n",
      "Epoch 5/8\n",
      "11s - loss: 3.5373 - acc: 0.7802\n",
      "Epoch 6/8\n",
      "11s - loss: 3.9627 - acc: 0.7539\n",
      "Epoch 7/8\n",
      "11s - loss: 4.0363 - acc: 0.7493\n",
      "Epoch 8/8\n",
      "11s - loss: 3.2996 - acc: 0.7951\n",
      "Epoch 1/15\n",
      "11s - loss: 3.4535 - acc: 0.7855\n",
      "Epoch 2/15\n",
      "11s - loss: 3.2128 - acc: 0.8006\n",
      "Epoch 3/15\n",
      "11s - loss: 3.8646 - acc: 0.7600\n",
      "Epoch 4/15\n",
      "11s - loss: 4.3662 - acc: 0.7289\n",
      "Epoch 5/15\n",
      "11s - loss: 4.1644 - acc: 0.7414\n",
      "Epoch 6/15\n",
      "11s - loss: 4.2625 - acc: 0.7354\n",
      "Epoch 7/15\n",
      "12s - loss: 4.0654 - acc: 0.7475\n",
      "Epoch 8/15\n",
      "11s - loss: 3.6092 - acc: 0.7759\n",
      "Epoch 9/15\n",
      "11s - loss: 3.5713 - acc: 0.7783\n",
      "Epoch 10/15\n",
      "11s - loss: 3.9905 - acc: 0.7523\n",
      "Epoch 11/15\n",
      "11s - loss: 3.6639 - acc: 0.7726\n",
      "Epoch 12/15\n",
      "11s - loss: 3.4339 - acc: 0.7868\n",
      "Epoch 13/15\n",
      "11s - loss: 3.7092 - acc: 0.7698\n",
      "Epoch 14/15\n",
      "12s - loss: 3.1693 - acc: 0.8032\n",
      "Epoch 15/15\n",
      "12s - loss: 3.8553 - acc: 0.7607\n",
      "Epoch 1/2\n",
      "13s - loss: 4.3099 - acc: 0.7154\n",
      "Epoch 2/2\n",
      "11s - loss: 6.6526 - acc: 0.5860\n",
      "Epoch 1/4\n",
      "11s - loss: 6.4375 - acc: 0.6001\n",
      "Epoch 2/4\n",
      "11s - loss: 6.2457 - acc: 0.6119\n",
      "Epoch 3/4\n",
      "11s - loss: 6.8557 - acc: 0.5741\n",
      "Epoch 4/4\n",
      "11s - loss: 6.4686 - acc: 0.5983\n",
      "Epoch 1/8\n",
      "11s - loss: 7.2796 - acc: 0.5480\n",
      "Epoch 2/8\n",
      "11s - loss: 6.7127 - acc: 0.5833\n",
      "Epoch 3/8\n",
      "11s - loss: 6.9764 - acc: 0.5669\n",
      "Epoch 4/8\n",
      "11s - loss: 6.4591 - acc: 0.5990\n",
      "Epoch 5/8\n",
      "11s - loss: 6.3603 - acc: 0.6052\n",
      "Epoch 6/8\n",
      "11s - loss: 7.0587 - acc: 0.5619\n",
      "Epoch 7/8\n",
      "11s - loss: 6.6259 - acc: 0.5889\n",
      "Epoch 8/8\n",
      "11s - loss: 7.2007 - acc: 0.5532\n",
      "Epoch 1/15\n",
      "11s - loss: 6.5440 - acc: 0.5940\n",
      "Epoch 2/15\n",
      "11s - loss: 7.0471 - acc: 0.5627\n",
      "Epoch 3/15\n",
      "11s - loss: 6.0867 - acc: 0.6223\n",
      "Epoch 4/15\n",
      "11s - loss: 6.3752 - acc: 0.6044\n",
      "Epoch 5/15\n",
      "11s - loss: 6.1443 - acc: 0.6187\n",
      "Epoch 6/15\n",
      "11s - loss: 6.0950 - acc: 0.6218\n",
      "Epoch 7/15\n",
      "11s - loss: 6.3840 - acc: 0.6039\n",
      "Epoch 8/15\n",
      "11s - loss: 6.2775 - acc: 0.6104\n",
      "Epoch 9/15\n",
      "11s - loss: 6.2669 - acc: 0.6111\n",
      "Epoch 10/15\n",
      "11s - loss: 6.2266 - acc: 0.6137\n",
      "Epoch 11/15\n",
      "11s - loss: 6.0710 - acc: 0.6233\n",
      "Epoch 12/15\n",
      "11s - loss: 6.4708 - acc: 0.5985\n",
      "Epoch 13/15\n",
      "11s - loss: 6.7211 - acc: 0.5830\n",
      "Epoch 14/15\n",
      "11s - loss: 6.2781 - acc: 0.6105\n",
      "Epoch 15/15\n",
      "11s - loss: 6.1501 - acc: 0.6184\n",
      "Epoch 1/2\n",
      "13s - loss: 2.9203 - acc: 0.8011\n",
      "Epoch 2/2\n",
      "12s - loss: 4.4550 - acc: 0.7215\n",
      "Epoch 1/4\n",
      "12s - loss: 3.6338 - acc: 0.7734\n",
      "Epoch 2/4\n",
      "12s - loss: 3.5135 - acc: 0.7812\n",
      "Epoch 3/4\n",
      "12s - loss: 3.5432 - acc: 0.7797\n",
      "Epoch 4/4\n",
      "12s - loss: 3.4024 - acc: 0.7885\n",
      "Epoch 1/8\n",
      "11s - loss: 3.3663 - acc: 0.7909\n",
      "Epoch 2/8\n",
      "12s - loss: 3.5774 - acc: 0.7777\n",
      "Epoch 3/8\n",
      "12s - loss: 2.7547 - acc: 0.8288\n",
      "Epoch 4/8\n",
      "11s - loss: 2.3395 - acc: 0.8546\n",
      "Epoch 5/8\n",
      "11s - loss: 3.1188 - acc: 0.8063\n",
      "Epoch 6/8\n",
      "12s - loss: 3.7657 - acc: 0.7662\n",
      "Epoch 7/8\n",
      "12s - loss: 3.8277 - acc: 0.7624\n",
      "Epoch 8/8\n",
      "11s - loss: 3.9633 - acc: 0.7539\n",
      "Epoch 1/15\n",
      "12s - loss: 3.1195 - acc: 0.8063\n",
      "Epoch 2/15\n",
      "12s - loss: 3.2536 - acc: 0.7980\n",
      "Epoch 3/15\n",
      "12s - loss: 2.8769 - acc: 0.8214\n",
      "Epoch 4/15\n",
      "11s - loss: 3.2613 - acc: 0.7975\n",
      "Epoch 5/15\n",
      "12s - loss: 3.0197 - acc: 0.8126\n",
      "Epoch 6/15\n",
      "11s - loss: 3.1080 - acc: 0.8071\n",
      "Epoch 7/15\n",
      "12s - loss: 2.5444 - acc: 0.8420\n",
      "Epoch 8/15\n",
      "12s - loss: 2.4966 - acc: 0.8450\n",
      "Epoch 9/15\n",
      "11s - loss: 2.6137 - acc: 0.8378\n",
      "Epoch 10/15\n",
      "12s - loss: 3.0706 - acc: 0.8093\n",
      "Epoch 11/15\n",
      "12s - loss: 3.2488 - acc: 0.7983\n",
      "Epoch 12/15\n",
      "12s - loss: 3.0039 - acc: 0.8136\n",
      "Epoch 13/15\n",
      "12s - loss: 3.1022 - acc: 0.8074\n",
      "Epoch 14/15\n",
      "11s - loss: 2.7895 - acc: 0.8268\n",
      "Epoch 15/15\n",
      "11s - loss: 3.0417 - acc: 0.8112\n",
      "Epoch 1/2\n",
      "14s - loss: 2.9671 - acc: 0.7998\n",
      "Epoch 2/2\n",
      "12s - loss: 3.1764 - acc: 0.8012\n",
      "Epoch 1/4\n",
      "12s - loss: 4.5325 - acc: 0.7178\n",
      "Epoch 2/4\n",
      "11s - loss: 4.4104 - acc: 0.7255\n",
      "Epoch 3/4\n",
      "12s - loss: 3.8703 - acc: 0.7594\n",
      "Epoch 4/4\n",
      "12s - loss: 3.6114 - acc: 0.7757\n",
      "Epoch 1/8\n",
      "12s - loss: 4.6174 - acc: 0.7130\n",
      "Epoch 2/8\n",
      "12s - loss: 5.5701 - acc: 0.6541\n",
      "Epoch 3/8\n",
      "12s - loss: 6.3241 - acc: 0.6074\n",
      "Epoch 4/8\n",
      "12s - loss: 5.4234 - acc: 0.6633\n",
      "Epoch 5/8\n",
      "11s - loss: 4.8736 - acc: 0.6973\n",
      "Epoch 6/8\n",
      "12s - loss: 4.4218 - acc: 0.7256\n",
      "Epoch 7/8\n",
      "12s - loss: 5.2271 - acc: 0.6755\n",
      "Epoch 8/8\n",
      "11s - loss: 4.6050 - acc: 0.7141\n",
      "Epoch 1/15\n",
      "12s - loss: 4.7308 - acc: 0.7064\n",
      "Epoch 2/15\n",
      "12s - loss: 5.1222 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "12s - loss: 4.4516 - acc: 0.7237\n",
      "Epoch 4/15\n",
      "12s - loss: 4.5076 - acc: 0.7201\n",
      "Epoch 5/15\n",
      "12s - loss: 4.4735 - acc: 0.7224\n",
      "Epoch 6/15\n",
      "12s - loss: 4.7260 - acc: 0.7067\n",
      "Epoch 7/15\n",
      "12s - loss: 4.7088 - acc: 0.7077\n",
      "Epoch 8/15\n",
      "12s - loss: 5.0583 - acc: 0.6860\n",
      "Epoch 9/15\n",
      "12s - loss: 3.8541 - acc: 0.7608\n",
      "Epoch 10/15\n",
      "12s - loss: 4.5709 - acc: 0.7163\n",
      "Epoch 11/15\n",
      "12s - loss: 4.5797 - acc: 0.7158\n",
      "Epoch 12/15\n",
      "12s - loss: 4.4302 - acc: 0.7251\n",
      "Epoch 13/15\n",
      "12s - loss: 4.1760 - acc: 0.7409\n",
      "Epoch 14/15\n",
      "12s - loss: 4.2978 - acc: 0.7332\n",
      "Epoch 15/15\n",
      "11s - loss: 4.1069 - acc: 0.7451\n"
     ]
    }
   ],
   "source": [
    "ensemble_model=[ensemble() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/vishnu/Documents/mnist\"\n",
    "model_path = path + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn-mnist23-'+str(i)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#evals = np.array([m.evaluate(X_test, y_test, batch_size=256) for m in models])\n",
    "\n",
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])\n",
    "all_preds.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
